# copy this file to a file called config.py and customize for your own purposes

# customize the list of domains that often contain email you want to keep (like bills, personal emails, etc)
# domains are what occur after the @ sign in an email address;
# these will be ranked lower (less spammy) than non-safe domains
SAFE_DOMAINS = ["gmail.com", "yahoo.com", "email.att-mail.com", "google.com"]


# customize the list of emails and gmail labels to exclude from your analysis because they are emails you want to keep
IGNORE_EMAILS = ["hit-reply@linkedin.com",
                 "orders@eventbrite.com", "grandma@aol.com", "me@work.com"]
IGNORE_LABELS = ["_invoices"] # None to analyze ALL email, else a list of labels you want to exclude from analysis (you will keep these)=
INCLUDE_LABELS = [] # None to analyze ALL email, else a list of ONLY labels you want to include in analysis
INCLUDE_CATEGORIES = ["updates"]  # None to include ALL, else a list of ONLY the categories you want to analyze, e.g.  ["updates", "promotions"]

# years of email you want to analyze
# =====
EARLIEST_YEAR = 2004
# set to latest year of email to analyze, or None to include up to today
LATEST_YEAR = None
# set number of years to summarize at a time, or None to summarize once across all years
NUM_YEARS_PER_BATCH = None
REQUESTS_PER_BATCH = 1000  # have to throttle batching now to avoid triggering Google API rate limiting, all good things must end
WAIT_PER_BATCH = REQUESTS_PER_BATCH / (REQUESTS_PER_BATCH*1000) # seconds between batch executions, going smaller than this doesn't really help

# ====
# how many extra examples per frequent sender you want printed
NUM_EXAMPLES_PER_LINE = 3
# during analysis, show progress
NUM_EMAILS_PER_PROGRESS_UPDATE = 500
#comment out MAX_EMAILS_TO_PARSE to do all
MAX_EMAILS_TO_PARSE = 20000
MIN_FREQ_TO_DISPLAY = 8

